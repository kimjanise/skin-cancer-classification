{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T580eYXiinwZ"
      },
      "source": [
        "Assignment: https://www.cs.cmu.edu/~10315/10315_S24_Mini_Project.pdf\n",
        "\n",
        "**Title:** Prediction Confidence in Cancer Diagnoses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jO9s-E4OaVtj"
      },
      "outputs": [],
      "source": [
        "training_flag = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZ34W1uZaV_J"
      },
      "source": [
        "**Model Card:**\n",
        "\n",
        "**1) Task Input and Output**\n",
        "\n",
        "Input: The model takes as input images of skin lesions. Each image is represented as a 3D array of pixel values, indicating the color intensity of each pixel.\n",
        "\n",
        "Output: The model predicts the diagnosis of the skin lesion based on the input image. The diagnosis is classified into different categories, representing different types of skin cancer.\n",
        "\n",
        "**2) Training Data**\n",
        "\n",
        "The model is trained on the HAM10000 dataset, which contains 10,015 dermatoscopic images of skin lesions, labeled with ground truth diagnoses. The dataset includes seven different types of skin lesions, including melanoma, melanocytic nevi, basal cell carcinoma, actinic keratoses, benign keratosis-like lesions, dermatofibroma, and vascular lesions.\n",
        "\n",
        "**3) Intended Use**\n",
        "\n",
        "The model is intended to assist dermatologists and healthcare professionals in diagnosing skin lesions. It is designed to provide a preliminary assessment based on dermatoscopic images, which can help guide further clinical evaluation and treatment decisions. The primary users of the model would be healthcare professionals, including dermatologists, general practitioners, and other medical professionals involved in skin cancer diagnosis and treatment.  The model can be used as a decision support tool to aid in the early detection of skin cancer and other skin lesions. It can help prioritize cases for further evaluation and potentially reduce the number of unnecessary biopsies.  The model's predictions are based on the information present in the input images and do not capture all relevant clinical information, so it is important for healthcare professionals to use the model's predictions in conjunction with their clinical judgment and other diagnostic tools.\n",
        "\n",
        "**4) Risks**\n",
        "\n",
        "The dataset is imbalanced, with certain classes of skin lesions being underrepresented compared to others, which could lead to biased model predictions and lower performance on minority classes. Additionally, data could me mislabled as there could be some diagnostic error within the dataset.\n",
        "The use of medical data also raises ethical considerations, including patient privacy and consent. It is also difficult to interpret decisions of a CNN model, so we cannot be sure of what exactly is influencing a decisions. There is a risk of bias in the dataset, which could result in unfair or discriminatory outcomes. From a visual inspection of the dataset, a supermajority of the photos include a white or fair-skinned patients, so the model will likely perfom a lot worse for people with darker skin."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjSVESo9i7Zq"
      },
      "source": [
        "**Introduction: What is your project about? What problem are you trying to solve? Describe the dataset that you used and the inputs/outputs of the problem.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPJrgzYPc5F_"
      },
      "source": [
        "The goal of the project is to compare the confidence that different models have in classifying different images of skin lesions by their type of cancer diagnosis.  To do so, we use logistic regression and a convolutional neural network.  For both model types, we will input a collection of multi-source dermatoscopic images of pigmented lesions and output a vector with classification probabilities for different diagnostic categories: actinic keratoses and intraepithelial carcinoma / Bowen's disease, basal cell carcinoma, benign keratosis-like lesions, dermatofibroma, melanoma, melanocytic nevi and vascular lesions.  The diagnostic category with the highest probability is the predicted diagnosis of the model, and we will compare the different levels of confidence that each model has in its predictions.  We will also compare how different activation functions within the convolution neural network will impact the confidence rates.\n",
        "\n",
        "Experimental Question: How do different activation functions (e.g. softmax, ReLU, sigmoid) in a convolutional neural network impact the confidence in predicted classifications?\n",
        "\n",
        "Techniques: We plan to implement a convolution neural network and logistic regression to compare the relative confidence that each type of model has in the classification prediction.  The first model we will utilize is the logistic regression model.  The logistic regression model, as we’ve covered in this course, is a discriminative classification model that returns a real value for an input that is meant to model the probability of that data point belonging to each class.  The final classification made by the model is determined by identifying the class that is associated with the highest probability predicted by the model, indicating that the data point most likely belongs to that respective class.  We selected the logistic regression model as we’ve identified that our project is essentially a classification task of different skin lesions by their type of cancer diagnosis.  The logistic regression model is easy to interpret due to its simplicity and typically less demanding and more efficient than more complex models, setting an appropriate baseline or standard to compare the performance of other models against.\n",
        "For the convolutional neural network, we will use our experimental question, of which activation to use, to fine tune the model to compare the results with the logistic regression model.  This model was selected because it is generally significantly more complex than logistic regression models since it is essentially a deep neural network model with multiple layers (i.e. convolutional layer, pooling layer, etc.) that can be heavily fine-tuned.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mS2S6D5uVxdG"
      },
      "source": [
        "**Methods:**\n",
        "\n",
        "Logistic Regression We use logistic regression as a baseline model because of its simplicity. Each image is input into the model, which outputs a probability for various cancer diagnoses. The highest probability indicates the most likely diagnosis.\n",
        "\n",
        "*Convolutional Neural Network * The CNN will experiment with activation functions, ReLU, softmax and sigmoid to assess their impact on model confidence and accuracy. The network includes 5 convolutional layers with pooling, two more fully connected layers and an output layer to bring it together. We tailored the model to enhance feature extraction from the images, making it ideal for tasks like lesion classification.\n",
        "\n",
        "Comparative Analysis We will compare the confidence and reliability of predictions between the logistic regression model and the CNN, focusing on how different activation functions influence the CNN’s performance. This analysis will help identify the most effective model for accurate cancer image classification."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lLC-gSUZAGm"
      },
      "source": [
        "# Get Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T_uv08vIMnvf"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/kimjanise/315-mini-project.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "VYloiGxGOPi0",
        "outputId": "46bdf824-d3c4-4086-e474-28b6a8c6600b"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "shutil.move('/content/315-mini-project/HAM10000_metadata.csv', '/content')\n",
        "shutil.move('/content/315-mini-project/kaggle.json', '/content')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G9G2o5s4KHjg"
      },
      "outputs": [],
      "source": [
        "!pip install kaggle\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BD1YEdH_n7I3"
      },
      "outputs": [],
      "source": [
        "!kaggle datasets download -d kmader/skin-cancer-mnist-ham10000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jWyGebQMokG_"
      },
      "outputs": [],
      "source": [
        "!unzip skin-cancer-mnist-ham10000.zip -d /content/skin-cancer-data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghRiiqXmZEgA"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KnPgeLi-3E-9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from numpy.linalg import inv\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A1bpzu51qryx"
      },
      "outputs": [],
      "source": [
        "metadata = pd.read_csv('../content/HAM10000_metadata.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgGQpoUaX45f"
      },
      "source": [
        "**Data Processing:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PLp0cYuvhqYI"
      },
      "outputs": [],
      "source": [
        "# lesion names are given in the description of the dataset\n",
        "lesion_type_dict = {\n",
        "    'nv': 'Melanocytic nevi',\n",
        "    'mel': 'Melanoma',\n",
        "    'bkl': 'Benign keratosis-like lesions ',\n",
        "    'bcc': 'Basal cell carcinoma',\n",
        "    'akiec': 'Actinic keratoses',\n",
        "    'vasc': 'Vascular lesions',\n",
        "    'df': 'Dermatofibroma'\n",
        "}\n",
        "\n",
        "lesion_ID_dict = {\n",
        "    'nv': 0,\n",
        "    'mel': 1,\n",
        "    'bkl': 2,\n",
        "    'bcc': 3,\n",
        "    'akiec': 4,\n",
        "    'vasc': 5,\n",
        "    'df': 6\n",
        "}\n",
        "\n",
        "lesion_names = ['Melanocytic nevi','Melanoma','Benign keratosis-like lesions ',\n",
        "               'Basal cell carcinoma','Actinic keratoses','Vascular lesions',\n",
        "               'Dermatofibroma']\n",
        "\n",
        "lesion_names_short = ['nv','mel','bkl','bcc','akiec','vasc','df']\n",
        "\n",
        "metadata['lesion_type']=metadata['dx'].map(lesion_type_dict)\n",
        "metadata['lesion_ID'] = metadata['dx'].map(lesion_ID_dict)\n",
        "\n",
        "metadata['lesion_type'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J7NnauBqvZwF"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from cv2 import imread, resize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cp1hVfW9vt4T"
      },
      "outputs": [],
      "source": [
        "X = []\n",
        "y = []\n",
        "lista1 = os.listdir('/content/skin-cancer-data/HAM10000_images_part_1')\n",
        "lista2 = os.listdir('/content/skin-cancer-data/HAM10000_images_part_2')\n",
        "#import images from folder 1\n",
        "for i in range(len(lista1)):\n",
        "    fname_image = lista1[i]\n",
        "    fname_ID = fname_image.replace('.jpg','')\n",
        "    #features\n",
        "    file_to_read =os.path.join('/content/skin-cancer-data/HAM10000_images_part_1',fname_image)\n",
        "    img = imread(file_to_read)\n",
        "    img = resize(img, (100,100))\n",
        "    X.append(img)\n",
        "    #targets\n",
        "    output = np.array(metadata[metadata['image_id'] == fname_ID].lesion_ID)\n",
        "    y.append(output[0])\n",
        "\n",
        "for i in range(len(lista2)):\n",
        "    fname_image = lista2[i]\n",
        "    fname_ID = fname_image.replace('.jpg','')\n",
        "    #features\n",
        "    file_to_read =os.path.join('/content/skin-cancer-data/HAM10000_images_part_2',fname_image)\n",
        "    img = imread(file_to_read)\n",
        "    img = resize(img, (100,100))\n",
        "    X.append(img)\n",
        "    #targets\n",
        "    output = np.array(metadata[metadata['image_id'] == fname_ID].lesion_ID)\n",
        "    y.append(output[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xCzXv5sBhBbn"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "y_train = to_categorical(y, num_classes=7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c6yzRaKThH5F"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_train, test_size=0.2, random_state=50, stratify=y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x8ZSMFL8hJnD"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(1, 7, figsize=(30, 30))\n",
        "for i in range(7):\n",
        "    ax[i].set_axis_off()\n",
        "    ax[i].imshow(X_train[i])\n",
        "    ax[i].set_title(lesion_names[np.argmax(y_train[i])])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kQalqksohM4o"
      },
      "outputs": [],
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "y_id = np.array(metadata['lesion_ID'])\n",
        "\n",
        "# compute weights for the loss function, because the problem is unbalanced\n",
        "class_weights = np.around(compute_class_weight(class_weight='balanced',classes=np.unique(y_id),y=y),2)\n",
        "class_weights = dict(zip(np.unique(y_id),class_weights))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dqmxz1PZXOkG"
      },
      "source": [
        "**Logistic Regression Model:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "I62tf9C5XO_S",
        "outputId": "ce0002aa-f007-4fbb-fbce-ab76c29963f0"
      },
      "outputs": [],
      "source": [
        "# dimensionality reduction and flattening to fit the input of a logistic regression model and enable convergence\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "X_train_logreg = np.array([np.matrix.flatten(np.array([[np.mean(y) for y in x] for x in datapoint])) for datapoint in X_train])\n",
        "y_train_logreg = np.array([np.argmax(row) for row in y_train])\n",
        "X_test_logreg = np.array([np.matrix.flatten(np.array([[np.mean(y) for y in x] for x in datapoint])) for datapoint in X_test])\n",
        "y_test_logreg = np.array([np.argmax(row) for row in y_test])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kvoqVsVKr25g"
      },
      "outputs": [],
      "source": [
        "logreg = LogisticRegression(max_iter=10000, tol=0.1, class_weight=class_weights).fit(X_train_logreg, y_train_logreg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgUuEACqu1mF",
        "outputId": "29db7b19-6c61-4735-f23e-79d6a5944abe"
      },
      "outputs": [],
      "source": [
        "scores = logreg.score(X_test_logreg, y_test_logreg)\n",
        "scores\n",
        "# print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "id": "Hr-Vbl6qXO5H",
        "outputId": "a90efa22-a971-40a5-8460-f848f6d278b7"
      },
      "outputs": [],
      "source": [
        "from sklearn import metrics\n",
        "y_pred_logreg = logreg.predict(X_test_logreg)\n",
        "cnf_matrix = metrics.confusion_matrix(y_test_logreg, y_pred_logreg)\n",
        "cnf_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "id": "8F1kyJrG03zK",
        "outputId": "b458961b-4610-45b1-8f90-612aa14190ec"
      },
      "outputs": [],
      "source": [
        "y_hat_logreg = logreg.predict_proba(X_test_logreg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CWDTiHSDa9Zc"
      },
      "outputs": [],
      "source": [
        "# Loading Pre-trained models\n",
        "\n",
        "# modelSoftmax = Model()\n",
        "# load_model_from_file = f'./content/pretrained_models/pretrained_softmax_model.h5'\n",
        "# print(f'Loding model from {load_model_from_file}')\n",
        "# modelSoftmax.load_state_dict(torch.load(load_model_from_file, map_location=torch.device(trainer.device)))\n",
        "\n",
        "from keras.models import load_model\n",
        "modelSoftmax = load_model('./content/pretrained_models/pretrained_softmax_model.h5')\n",
        "\n",
        "# model_dir = '/content/pretrained_models'\n",
        "# os.makedirs(model_dir, exist_ok=True)\n",
        "# model_path = os.path.join(model_dir, 'pretrained_softmax_model.h5')  # h5 is a common format for Keras models\n",
        "# modelSoftmax.save(model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "pKjgKXehMgRw",
        "outputId": "7e9b6745-ed7b-4bdb-d0a8-185d400a293b"
      },
      "outputs": [],
      "source": [
        "# Accuracy Comparison\n",
        "model_names = [\"Logistic Regression\", \"CNN with ReLU\", \"CNN with Sigmoid\", \"CNN with Softmax\"]\n",
        "model_train_accuracy = []\n",
        "model_test_accuracy = []\n",
        "\n",
        "X_axis = np.arange(len(lesion_names_short))\n",
        "plt.bar(X_axis - 0.2, model_train_accuracy, 0.4, label = 'Train Accuracy')\n",
        "plt.bar(X_axis + 0.2, model_test_accuracy, 0.4, label = 'Test Accuracy')\n",
        "plt.xticks(X_axis, model_names)\n",
        "plt.xlabel(\"Model Type\")\n",
        "plt.ylabel(\"Percentage\")\n",
        "plt.title(\"Train and Test Accuracy Across Models\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7LRmlEvCG2Ub"
      },
      "outputs": [],
      "source": [
        "# Prediction Confidence Comparison\n",
        "y_pred_cnn_relu = modelRelu.predict(X_test)\n",
        "y_hat_cnn_relu = modelRelu.predict_proba(X_test)\n",
        "y_pred_cnn_sigmoid = modelSigmoid.predict(X_test)\n",
        "y_hat_cnn_sigmoid = modelSigmoid.predict_proba(X_test)\n",
        "y_pred_cnn_softmax = modelSoftmax.predict(X_test)\n",
        "y_hat_cnn_softmax = modelSoftmax.predict_proba(X_test)\n",
        "\n",
        "logreg_avg_confidence = np.zeros()\n",
        "cnn_relu_avg_confidence = np.zeros()\n",
        "cnn_sigmoid_avg_confidence = np.zeros()\n",
        "cnn_softmax_avg_confidence = np.zeros()\n",
        "for i in range(lesion_names_short):\n",
        "  logreg_avg_confidence[i] = np.mean(y_hat_logreg[y_pred_logreg == i])\n",
        "  cnn_relu_avg_confidence[i] = np.mean(y_hat_cnn_relu[y_pred_cnn_relu == i])\n",
        "  cnn_sigmoid_avg_confidence[i] = np.mean(y_hat_cnn_sigmoid[y_pred_cnn_sigmoid == i])\n",
        "  cnn_softmax_avg_confidence[i] = np.mean(y_hat_cnn_softmax[y_pred_cnn_softmax == i])\n",
        "\n",
        "X_axis = np.arange(len(lesion_names_short))\n",
        "plt.bar(X_axis - 0.3, logreg_avg_confidence, 0.2, label = 'Logistic Regression')\n",
        "plt.bar(X_axis - 0.1, cnn_relu_avg_confidence, 0.2, label = 'CNN with ReLU')\n",
        "plt.bar(X_axis + 0.1, cnn_sigmoid_avg_confidence, 0.2, label = 'CNN with Sigmoid')\n",
        "plt.bar(X_axis + 0.3, cnn_softmax_avg_confidence, 0.2, label = 'CNN with Softmax')\n",
        "plt.xticks(X_axis, lesion_names_short)\n",
        "plt.xlabel(\"Class\")\n",
        "plt.ylabel(\"Confidence in Prediction\")\n",
        "plt.title(\"Average Confidence in Class Predictions\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JK62HnDhNh9n"
      },
      "outputs": [],
      "source": [
        "# Training Loss Analysis\n",
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "plt.plot(range(1, len(relu_train_loss) + 1), relu_train_loss, color='b', label='CNN with ReLu')\n",
        "plt.plot(range(1, len(relu_train_loss) + 1), sigmoid_train_loss, color='r', label='CNN with Sigmoid')\n",
        "plt.plot(range(1, len(relu_train_loss) + 1), softmax_train_loss, color='g', label='CNN with Softmax')\n",
        "\n",
        "plt.title('Training Loss Across CNN Models')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvseGGragD16"
      },
      "source": [
        "**CNN Models:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "veNgSWjlhMgY"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras.models import Sequential, load_model, Model\n",
        "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
        "# from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Activation\n",
        "# from keras.layers import Conv2D,BatchNormalization,MaxPool2D,Flatten,Dense\n",
        "from keras.layers import Conv2D, MaxPool2D, Dense, Input, Activation, Dropout, GlobalAveragePooling2D, \\\n",
        "    BatchNormalization, concatenate, AveragePooling2D, Flatten\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Er08_aqBLlpU"
      },
      "source": [
        "CNN Model with ReLu:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4OEzBrIQhPFe"
      },
      "outputs": [],
      "source": [
        "modelRelu = Sequential([\n",
        "    # 1st convolutional layer\n",
        "    Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), activation='relu', input_shape=(100,100,3)),\n",
        "    BatchNormalization(),\n",
        "    MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
        "    # 2nd convolutional layer\n",
        "    Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\"),\n",
        "    BatchNormalization(),\n",
        "    MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
        "    # 3rd convolutional layer\n",
        "    Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
        "    BatchNormalization(),\n",
        "    # 4th convolutional layer\n",
        "    Conv2D(filters=384, kernel_size=(1,1), strides=(1,1), activation='relu', padding=\"same\"),\n",
        "    BatchNormalization(),\n",
        "    # 5th convolutional layer\n",
        "    Conv2D(filters=256, kernel_size=(1,1), strides=(1,1), activation='relu', padding=\"same\"),\n",
        "    BatchNormalization(),\n",
        "    MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
        "    Flatten(),\n",
        "    # 6th, Dense layer\n",
        "    Dense(4096, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    # 7th Dense layer\n",
        "    Dense(4096, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    # 8th output layer\n",
        "    Dense(7, activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_D-z-i5vhTKq",
        "outputId": "7dc8e8ea-c891-4eb8-991d-6132b3ff5fc2"
      },
      "outputs": [],
      "source": [
        "# training\n",
        "early_stopping_monitor = EarlyStopping(patience=100,monitor='val_accuracy')\n",
        "model_checkpoint_callback = ModelCheckpoint(filepath='model.h5',\n",
        "                                            save_weights_only=False,\n",
        "                                            monitor='val_accuracy',\n",
        "                                            mode='auto',\n",
        "                                            save_best_only=True,\n",
        "                                            verbose=1)\n",
        "batch_size = 32\n",
        "epochs = 100\n",
        "optimizer = Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-3)\n",
        "modelRelu.compile(optimizer = optimizer, loss = 'categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "datagen = ImageDataGenerator(zoom_range = 0.2, horizontal_flip=True, shear_range=0.2)\n",
        "\n",
        "datagen.fit(X_train)\n",
        "\n",
        "history=modelRelu.fit(datagen.flow(X_train,y_train), epochs=epochs, batch_size=batch_size, shuffle=True, callbacks=[early_stopping_monitor,model_checkpoint_callback], validation_data=(X_test, y_test), class_weight=class_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "adyCpTeEhZFH"
      },
      "outputs": [],
      "source": [
        "scores = modelRelu.evaluate(X_test, y_test, verbose=1)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixncY5_RLps6"
      },
      "source": [
        "CNN Model with Sigmoid:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NAIZNdj1hZZf"
      },
      "outputs": [],
      "source": [
        "modelSigmoid = Sequential([\n",
        "    # 1st convolutional layer\n",
        "    Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), activation='sigmoid', input_shape=(100,100,3)),\n",
        "    BatchNormalization(),\n",
        "    MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
        "    # 2nd convolutional layer\n",
        "    Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='sigmoid', padding=\"same\"),\n",
        "    BatchNormalization(),\n",
        "    MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
        "    # 3rd convolutional layer\n",
        "    Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='sigmoid', padding=\"same\"),\n",
        "    BatchNormalization(),\n",
        "    # 4th convolutional layer\n",
        "    Conv2D(filters=384, kernel_size=(1,1), strides=(1,1), activation='sigmoid', padding=\"same\"),\n",
        "    BatchNormalization(),\n",
        "    # 5th convolutional layer\n",
        "    Conv2D(filters=256, kernel_size=(1,1), strides=(1,1), activation='sigmoid', padding=\"same\"),\n",
        "    BatchNormalization(),\n",
        "    MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
        "    Flatten(),\n",
        "    # 6th, Dense layer\n",
        "    Dense(4096, activation='sigmoid'),\n",
        "    Dropout(0.5),\n",
        "    # 7th Dense layer\n",
        "    Dense(4096, activation='sigmoid'),\n",
        "    Dropout(0.5),\n",
        "    # 8th output layer\n",
        "    Dense(7, activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zIjozbLgLN_7"
      },
      "outputs": [],
      "source": [
        "# training\n",
        "early_stopping_monitor = EarlyStopping(patience=100,monitor='val_accuracy')\n",
        "model_checkpoint_callback = ModelCheckpoint(filepath='model.h5',\n",
        "                                            save_weights_only=False,\n",
        "                                            monitor='val_accuracy',\n",
        "                                            mode='auto',\n",
        "                                            save_best_only=True,\n",
        "                                            verbose=1)\n",
        "batch_size = 32\n",
        "epochs = 100\n",
        "optimizer = Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-3)\n",
        "modelSigmoid.compile(optimizer = optimizer, loss = 'categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "datagen = ImageDataGenerator(zoom_range = 0.2, horizontal_flip=True, shear_range=0.2)\n",
        "\n",
        "datagen.fit(X_train)\n",
        "\n",
        "history=modelSigmoid.fit(datagen.flow(X_train,y_train), epochs=epochs, batch_size=batch_size, shuffle=True, callbacks=[early_stopping_monitor,model_checkpoint_callback], validation_data=(X_test, y_test), class_weight=class_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UsqIdJDLLiPa"
      },
      "outputs": [],
      "source": [
        "scores = modelSigmoid.evaluate(X_test, y_test, verbose=1)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2rrCDbyLsX2"
      },
      "source": [
        "CNN Model with Softmax:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-YTjGA7KLvmT"
      },
      "outputs": [],
      "source": [
        "modelSoftmax = Sequential([\n",
        "    # 1st convolutional layer\n",
        "    Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), activation='sigmoid', input_shape=(100,100,3)),\n",
        "    BatchNormalization(),\n",
        "    MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
        "    # 2nd convolutional layer\n",
        "    Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='sigmoid', padding=\"same\"),\n",
        "    BatchNormalization(),\n",
        "    MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
        "    # 3rd convolutional layer\n",
        "    Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='sigmoid', padding=\"same\"),\n",
        "    BatchNormalization(),\n",
        "    # 4th convolutional layer\n",
        "    Conv2D(filters=384, kernel_size=(1,1), strides=(1,1), activation='sigmoid', padding=\"same\"),\n",
        "    BatchNormalization(),\n",
        "    # 5th convolutional layer\n",
        "    Conv2D(filters=256, kernel_size=(1,1), strides=(1,1), activation='sigmoid', padding=\"same\"),\n",
        "    BatchNormalization(),\n",
        "    MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
        "    Flatten(),\n",
        "    # 6th, Dense layer\n",
        "    Dense(4096, activation='sigmoid'),\n",
        "    Dropout(0.5),\n",
        "    # 7th Dense layer\n",
        "    Dense(4096, activation='sigmoid'),\n",
        "    Dropout(0.5),\n",
        "    # 8th output layer\n",
        "    Dense(7, activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6_C_hFNyL3Cv"
      },
      "outputs": [],
      "source": [
        "# training\n",
        "early_stopping_monitor = EarlyStopping(patience=100,monitor='val_accuracy')\n",
        "model_checkpoint_callback = ModelCheckpoint(filepath='model.h5',\n",
        "                                            save_weights_only=False,\n",
        "                                            monitor='val_accuracy',\n",
        "                                            mode='auto',\n",
        "                                            save_best_only=True,\n",
        "                                            verbose=1)\n",
        "batch_size = 32\n",
        "epochs = 100\n",
        "optimizer = Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-3)\n",
        "modelSoftmax.compile(optimizer = optimizer, loss = 'categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "datagen = ImageDataGenerator(zoom_range = 0.2, horizontal_flip=True, shear_range=0.2)\n",
        "\n",
        "datagen.fit(X_train)\n",
        "\n",
        "history=modelSoftmax.fit(datagen.flow(X_train,y_train), epochs=epochs, batch_size=batch_size, shuffle=True, callbacks=[early_stopping_monitor,model_checkpoint_callback], validation_data=(X_test, y_test), class_weight=class_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_vljbuKdL6mt"
      },
      "outputs": [],
      "source": [
        "scores = modelSoftmax.evaluate(X_test, y_test, verbose=1)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzPr2bQiWDPa"
      },
      "source": [
        "**Results and Discussion:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ab2C-8nF0Ayc"
      },
      "source": [
        "analysis- The CNN with ReLU activation outperformed other models, achieving the highest accuracy of 71%. This result supports what we expected for ReLU in CNNs.\n",
        "\n",
        "The sigmoid and softmax activations in the CNN performed poorly, with accuracies of 52% and 48%, respectively. Softmax in a convolutional layer, typically used only in the output layer for multi-class classification, shows a misapplication, which resulted in the lowest performance.\n",
        "\n",
        "The logistic regression model performed reasonably well, considering its simplicity compared to neural networks, with an accuracy of 60%.​​ This was really surprising to us as we expected it to preform a lot worse than the CNNs. This makes it a quality baseline for comparison, indicating that complex models do not always yield better results.\n",
        "\n",
        "The results were somewhat expected, especially the superior performance of the CNN with ReLU compared to sigmoid and softmax activations. The underperformance of logistic regression compared to the best CNN configuration was anticipated due to the logistic model's linear nature, which limits its ability to capture complex patterns in image data as effectively as CNNs.\n",
        "The low performance of the softmax activation within the CNN was unexpected. We expected it to have a performance closer to the ReLU activation function and not do as poorly as it did.\n",
        "\n",
        "**Conclusion**\n",
        "Overall, the experimental results show the importance of choosing the right activation function and model architecture based on the task at hand. While CNNs with ReLU activation are generally more effective for image classification tasks, logistic regression provides a baseline. We were disappointed in the performance of the CNN with ReLU as we expected a higher accuracy.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gH5jTsjnhcB"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncKIBJaYjKHh"
      },
      "source": [
        "**References and Citations:**\n",
        "\n",
        "\n",
        "https://www.kaggle.com/datasets/kmader/skin-cancer-mnist-ham10000/data\n",
        "\n",
        "https://www.kaggle.com/code/harinagasaiperisetla/skin-lesion-ham10000-using-cnn\n",
        "\n",
        "https://machinelearningmastery.com/regression-tutorial-keras-deep-learning-library-python/\n",
        "\n",
        "https://machinelearningmastery.com/multinomial-logistic-regression-with-python/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-KPC4qpIvQCR"
      },
      "outputs": [],
      "source": [
        "# Model push\n",
        "!curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | sudo bash\n",
        "!sudo apt-get install git-lfs\n",
        "!git lfs install\n",
        "\n",
        "%cd /content/checkpoints/train\n",
        "!git clone https://{username}:{password}@github.com/{username}/{project}.git\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
